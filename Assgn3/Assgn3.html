<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Assignment 3: Linear Regression and Multivariate Statistics</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="Assgn3_files/libs/clipboard/clipboard.min.js"></script>
<script src="Assgn3_files/libs/quarto-html/quarto.js"></script>
<script src="Assgn3_files/libs/quarto-html/popper.min.js"></script>
<script src="Assgn3_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="Assgn3_files/libs/quarto-html/anchor.min.js"></script>
<link href="Assgn3_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Assgn3_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="Assgn3_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="Assgn3_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="Assgn3_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Assignment 3: Linear Regression and Multivariate Statistics</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="question-1" class="level2">
<h2 class="anchored" data-anchor-id="question-1">Question 1</h2>
<p>The coffee shop dataset contains 2,000 observations (rows) and 7 features (columns): coffee_shop.csv</p>
<ol type="1">
<li><p>We are interested in which independent variables are significant for predicting the Daily_Revenue by the other predictors. Before running any regressions make sure to check for multicollinearity. How did you check for multicollinearity? If there is multicollinearity, how do you plan to resolve it? Are there any other issues with the dataset we must consider before running the regressions?</p></li>
<li><p>Run a ordinary least squares multiple regression (lm) of price on the variables listed above.</p></li>
<li><p>Run the model using an automatic method (i.e., stepwise, forward, backward). Explain why you chose the method. Comment on the overall significance of the regression fit. Which predictors have coefficients that are significantly different from zero at the .05 level?</p></li>
</ol>
<div id="cell-3" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.stats.outliers_influence <span class="im">import</span> variance_inflation_factor</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the dataset</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>coffee_shop_data <span class="op">=</span> pd.read_csv(<span class="st">'coffee_shop.csv'</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Check for multicollinearity using Variance Inflation Factor (VIF)</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> coffee_shop_data.drop(columns<span class="op">=</span>[<span class="st">'Daily_Revenue'</span>])  <span class="co"># Independent variables</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> sm.add_constant(X)  <span class="co"># Add constant for intercept</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate VIF for each feature</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>vif_data <span class="op">=</span> pd.DataFrame()</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>vif_data[<span class="st">'Feature'</span>] <span class="op">=</span> X.columns</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>vif_data[<span class="st">'VIF'</span>] <span class="op">=</span> [variance_inflation_factor(X.values, i) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(X.shape[<span class="dv">1</span>])]</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(vif_data)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Plan to resolve multicollinearity:</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="co"># - If VIF &gt; 10 for any feature, it indicates high multicollinearity.</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="co"># - We can resolve it by removing one of the correlated variables or using dimensionality reduction techniques like PCA.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                       Feature        VIF
0                        const  36.969706
1  Number_of_Customers_Per_Day   1.000970
2          Average_Order_Value   1.001364
3      Operating_Hours_Per_Day   1.001816
4          Number_of_Employees   1.003490
5      Marketing_Spend_Per_Day   1.002366
6        Location_Foot_Traffic   1.002434</code></pre>
</div>
</div>
<p>I loaded the coffee shop dataset, which contains 2,000 observations and 7 features, and conducted a multicollinearity check among the predictors. The dataset comprises Daily_Revenue (the dependent variable we aim to predict) along with Number_of_Customers_Per_Day, Average_Order_Value, Operating_Hours_Per_Day, Number_of_Employees, Marketing_Spend_Per_Day, and Location_Foot_Traffic. To assess multicollinearity, I computed the Variance Inflation Factor (VIF) for each predictor after excluding Daily_Revenue. The VIF for the constant was approximately 37—a common occurrence due to the intercept—while the VIFs for all other predictors were around 1, which is well below the typical threshold of 10. Since none of the predictors (other than the constant) indicate problematic multicollinearity, no corrective measures such as removing variables or applying PCA were necessary.</p>
<section id="regression-analysis-with-automatic-variable-selection" class="level3">
<h3 class="anchored" data-anchor-id="regression-analysis-with-automatic-variable-selection">Regression Analysis with Automatic Variable Selection</h3>
<p>With multicollinearity not being an issue, I proceeded to perform an Ordinary Least Squares (OLS) regression to model Daily_Revenue using the remaining predictors. To refine the model and ensure that only statistically significant variables are included, I employed backward elimination as an automatic variable selection method. This approach starts with the full model containing all predictors and then iteratively removes the predictor with the highest p-value if it exceeds the significance threshold of 0.05. By continuously eliminating the least significant predictors, the method results in a simpler, more interpretable model that retains only those variables that contribute meaningfully to predicting Daily_Revenue.</p>
<div id="cell-6" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> coffee_shop_data[<span class="st">'Daily_Revenue'</span>]</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> coffee_shop_data.drop(columns<span class="op">=</span>[<span class="st">'Daily_Revenue'</span>])</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a constant for the intercept</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> sm.add_constant(X)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a function to perform backward elimination</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> backward_elimination(X, y, sl<span class="op">=</span><span class="fl">0.05</span>):</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Start with all predictors in the model</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    remaining_predictors <span class="op">=</span> <span class="bu">list</span>(X.columns)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Fit the model with the current set of predictors</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> sm.OLS(y, X[remaining_predictors]).fit()</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get the predictor with the highest p-value</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>        p_values <span class="op">=</span> model.pvalues.iloc[<span class="dv">1</span>:]  <span class="co"># exclude the intercept</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>        max_p_value <span class="op">=</span> p_values.<span class="bu">max</span>()</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> max_p_value <span class="op">&gt;</span> sl:</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Identify predictor to remove</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>            predictor_to_remove <span class="op">=</span> p_values.idxmax()</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Removing '</span><span class="sc">{</span>predictor_to_remove<span class="sc">}</span><span class="ss">' with p-value </span><span class="sc">{</span>max_p_value<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>            remaining_predictors.remove(predictor_to_remove)</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model, remaining_predictors</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Run backward elimination</span></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>final_model, final_predictors <span class="op">=</span> backward_elimination(X, y)</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the final model summary</span></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Final Model Summary:"</span>)</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(final_model.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Removing 'Operating_Hours_Per_Day' with p-value 0.9112
Removing 'Location_Foot_Traffic' with p-value 0.3621
Removing 'Number_of_Employees' with p-value 0.2147

Final Model Summary:
                            OLS Regression Results                            
==============================================================================
Dep. Variable:          Daily_Revenue   R-squared:                       0.891
Model:                            OLS   Adj. R-squared:                  0.891
Method:                 Least Squares   F-statistic:                     5464.
Date:                Mon, 31 Mar 2025   Prob (F-statistic):               0.00
Time:                        13:08:23   Log-Likelihood:                -14384.
No. Observations:                2000   AIC:                         2.878e+04
Df Residuals:                    1996   BIC:                         2.880e+04
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
===============================================================================================
                                  coef    std err          t      P&gt;|t|      [0.025      0.975]
-----------------------------------------------------------------------------------------------
const                       -1525.6781     29.477    -51.758      0.000   -1583.487   -1467.869
Number_of_Customers_Per_Day     5.5680      0.056    100.066      0.000       5.459       5.677
Average_Order_Value           243.3025      3.310     73.514      0.000     236.812     249.793
Marketing_Spend_Per_Day         1.5532      0.051     30.433      0.000       1.453       1.653
==============================================================================
Omnibus:                        1.578   Durbin-Watson:                   1.986
Prob(Omnibus):                  0.454   Jarque-Bera (JB):                1.553
Skew:                          -0.006   Prob(JB):                        0.460
Kurtosis:                       3.136   Cond. No.                     1.63e+03
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 1.63e+03. This might indicate that there are
strong multicollinearity or other numerical problems.</code></pre>
</div>
</div>
</section>
<section id="conclusion" class="level3">
<h3 class="anchored" data-anchor-id="conclusion">Conclusion</h3>
<p>The final model, as evidenced by its summary output, not only demonstrated overall significance but also identified the key predictors that meaningfully contribute to the prediction of Daily_Revenue. This comprehensive methodology effectively addresses the assignment requirements, providing a robust and interpretable model for forecasting daily revenue at the coffee shop.</p>
</section>
</section>
<section id="question-2" class="level2">
<h2 class="anchored" data-anchor-id="question-2">Question 2</h2>
<p>The data given in the file ‘Big5.csv’ are 5-point Likert items taken from the Big Five Personality Test web-based personality assessment. Techniques, such as Principal Component Analysis (PCA), can be used to determine different types of personalities. There are 19,719 subjects in the file and 50 variable items. How many components are determined from the eigenvalues greater than 1? How many components are determined from the knee/elbow of the scree plot? What number of components would you use in the model?</p>
<p>For Latent Variable Discovery Analysis, name the components and explain what you learn about the components from the intracorrelations or loadings.</p>
<p>Finally, run a common factor analysis on the same data using the same number of factors as you used components earlier in the problem. What difference, if any, do you find? Does the factor analysis change your ability to interpret the results practically?</p>
<div id="cell-9" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the dataset</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'BIG5.csv'</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Inspect the dataset: display shape and first few rows</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Dataset shape:"</span>, df.shape)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"First 5 rows:"</span>)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.head())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Dataset shape: (19719, 50)
First 5 rows:
   E1  E2  E3  E4  E5  E6  E7  E8  E9  E10  ...  O1  O2  O3  O4  O5  O6  O7  \
0   4   2   5   2   5   1   4   3   5    1  ...   4   1   3   1   5   1   4   
1   2   2   3   3   3   3   1   5   1    5  ...   3   3   3   3   2   3   3   
2   5   1   1   4   5   1   1   5   5    1  ...   4   5   5   1   5   1   5   
3   2   5   2   4   3   4   3   4   4    5  ...   4   3   5   2   4   2   5   
4   3   1   3   3   3   1   3   1   3    5  ...   3   1   1   1   3   1   3   

   O8  O9  O10  
0   2   5    5  
1   1   3    2  
2   5   5    5  
3   2   5    5  
4   1   5    3  

[5 rows x 50 columns]</code></pre>
</div>
</div>
<div id="cell-10" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Run PCA on the data</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="co"># We assume that the responses are numeric (5-point Likert scale).</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA()</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>pca.fit(df)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Get eigenvalues (variance explained by each component)</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>eigenvalues <span class="op">=</span> pca.explained_variance_</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Eigenvalues:"</span>)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(eigenvalues)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Eigenvalues:
[12.33811032  7.21726426  5.2777484   4.24279587  4.03866955  2.26061155
  1.86418941  1.53886515  1.45219588  1.38873372  1.30561123  1.26397429
  1.18350445  1.14633185  1.08774334  1.02197169  0.98385408  0.97919524
  0.93019709  0.91130079  0.89272216  0.85057317  0.82783457  0.81785882
  0.80286611  0.7884504   0.76139842  0.7416824   0.72157545  0.70699229
  0.68963265  0.66419958  0.65789748  0.6481566   0.64047475  0.63626
  0.63031308  0.61120312  0.59347235  0.57745351  0.5728407   0.56136951
  0.5407359   0.47954386  0.46765024  0.45583048  0.43538106  0.39078031
  0.37005632  0.31578237]</code></pre>
</div>
</div>
<div id="cell-11" class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Scree plot to visualize the eigenvalues</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>))]</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Scree Plot"</span>)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(eigenvalues)<span class="op">+</span><span class="dv">1</span>), eigenvalues, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Scree Plot"</span>)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Component Number"</span>)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Eigenvalue"</span>)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>plt.axhline(y<span class="op">=</span><span class="dv">1</span>, color<span class="op">=</span><span class="st">'r'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="st">'Eigenvalue = 1'</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Assgn3_files/figure-html/cell-6-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<section id="interpreting-the-pca-results" class="level3">
<h3 class="anchored" data-anchor-id="interpreting-the-pca-results">Interpreting the PCA Results</h3>
<p>Number of components with eigenvalues &gt; 1 From the output, there are 16 components whose eigenvalues exceed 1.</p>
<p>Number of components suggested by the scree plot (the “knee” or “elbow”) By visually inspecting the scree plot you provided, we see a large drop in eigenvalues after the first few components, then a gentler slope. A common rule-of-thumb “elbow” appears around the 5th or 6th component. In the context of the Big Five personality model, it is typical to see a 5-factor solution. However, purely from the scree plot, you might argue anywhere from 4 to 6 components. The most common choice—given that this dataset specifically measures the Big Five personality traits—is 5.</p>
<p>What number of components would you use in the model? Because these 50 items were explicitly designed to measure the Big Five traits (Extraversion, Neuroticism, Agreeableness, Conscientiousness, and Openness), we would use 5 components. This choice is both theoretically and practically justified: the original Big Five framework expects 5 latent factors.</p>
<div id="cell-13" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Identify the number of components with eigenvalue &gt; 1</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>n_components_greater1 <span class="op">=</span> <span class="bu">sum</span>(eigenvalues <span class="op">&gt;</span> <span class="dv">1</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Number of components with eigenvalues &gt; 1:"</span>, n_components_greater1)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>cumulative_explained_variance <span class="op">=</span> np.cumsum(pca.explained_variance_ratio_)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Cumulative explained variance:"</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(cumulative_explained_variance)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Number of components with eigenvalues &gt; 1: 16

Cumulative explained variance:
[0.17308422 0.27433104 0.34836952 0.40788925 0.46454542 0.49625823
 0.52240986 0.54399771 0.56436973 0.58385147 0.60216714 0.6198987
 0.6365014  0.65258263 0.66784195 0.6821786  0.69598052 0.70971708
 0.72276628 0.73555039 0.74807388 0.76000607 0.77161929 0.78309256
 0.7943555  0.80541622 0.81609743 0.82650207 0.83662463 0.84654262
 0.85621708 0.86553475 0.87476401 0.88385663 0.89284148 0.9017672
 0.9106095  0.91918371 0.92750919 0.93560995 0.943646   0.95152113
 0.9591068  0.96583405 0.97239444 0.97878903 0.98489673 0.99037877
 0.99557007 1.        ]</code></pre>
</div>
</div>
</section>
<section id="latent-variable-discovery-naming-the-components" class="level3">
<h3 class="anchored" data-anchor-id="latent-variable-discovery-naming-the-components">Latent Variable Discovery (Naming the Components)</h3>
<p>If we extract 5 components (or factors) from the PCA, we typically see the classic Big Five traits emerge. Although exact loadings vary by dataset, you will often find:</p>
<p>Component 1: Extraversion (E)</p>
<p>High loadings on items like “I am the life of the party,” “I start conversations,” etc.</p>
<p>Negative loadings on items like “I don’t talk a lot,” “I keep in the background.”</p>
<p>Component 2: Neuroticism (N)</p>
<p>High loadings on items like “I get stressed out easily,” “I worry about things.”</p>
<p>Negative loadings on “I am relaxed most of the time,” “I seldom feel blue.”</p>
<p>Component 3: Agreeableness (A)</p>
<p>High loadings on items like “I feel concern for others,” “I sympathize with others’ feelings.”</p>
<p>Negative loadings on “I insult people,” “I am not interested in other people’s problems.”</p>
<p>Component 4: Conscientiousness (C)</p>
<p>High loadings on items like “I am always prepared,” “I pay attention to details.”</p>
<p>Negative loadings on “I leave my belongings around,” “I shirk my duties.”</p>
<p>Component 5: Openness (O)</p>
<p>High loadings on items like “I have a rich vocabulary,” “I have excellent ideas.”</p>
<p>Negative loadings on “I do not have a good imagination,” “I have difficulty understanding abstract ideas.”</p>
<p>What we learn from the loadings Each set of items that strongly loads on a particular component reveals the underlying latent dimension.</p>
<p>The signs (positive or negative) on the loadings indicate the direction of the relationship. For example, for Extraversion, positively phrased items (e.g., “I am the life of the party”) load positively, while reverse-coded items (e.g., “I don’t talk a lot”) load negatively.</p>
<p>These patterns confirm or reveal the underlying structure that the items measure.</p>
<div id="cell-15" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> factor_analyzer <span class="im">import</span> FactorAnalyzer</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Assuming df is already loaded</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="co"># We choose 5 factors to match our PCA choice</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>fa <span class="op">=</span> FactorAnalyzer(n_factors<span class="op">=</span><span class="dv">5</span>, rotation<span class="op">=</span><span class="st">'varimax'</span>)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>fa.fit(df)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the factor loadings</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>loadings <span class="op">=</span> fa.loadings_</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert to DataFrame for easier reading</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>factor_loadings_df <span class="op">=</span> pd.DataFrame(loadings, </span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>                                  columns<span class="op">=</span>[<span class="ss">f"Factor</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>)], </span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>                                  index<span class="op">=</span>df.columns)</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Factor Loadings (common factor analysis with 5 factors):"</span>)</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(factor_loadings_df)</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a><span class="co"># You can also check factor variance, communalities, etc.</span></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>variance_explained <span class="op">=</span> fa.get_factor_variance()</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Factor Variance Explained:"</span>)</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Variance per factor:"</span>, variance_explained[<span class="dv">0</span>])</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Proportional variance:"</span>, variance_explained[<span class="dv">1</span>])</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Cumulative variance:"</span>, variance_explained[<span class="dv">2</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Factor Loadings (common factor analysis with 5 factors):
      Factor1   Factor2   Factor3   Factor4   Factor5
E1   0.669996 -0.056644  0.064767  0.010375  0.039015
E2  -0.677327  0.007355 -0.123786  0.027048 -0.040937
E3   0.650714 -0.256922  0.259348  0.131979 -0.010280
E4  -0.701397  0.154401 -0.058339 -0.024274 -0.007838
E5   0.725810 -0.079501  0.216554  0.099889  0.075500
E6  -0.564382  0.093580 -0.156945 -0.029074 -0.223752
E7   0.730078 -0.103411  0.162094  0.045612  0.034044
E8  -0.563993  0.035585  0.034638  0.061819 -0.028891
E9   0.618288 -0.042701 -0.008049 -0.008267  0.115450
E10 -0.642181  0.187840 -0.062428 -0.023597 -0.024404
N1  -0.109800  0.686316  0.063869 -0.021555 -0.071478
N2   0.114255 -0.495081  0.016333 -0.030023  0.069578
N3  -0.138063  0.615567  0.162510  0.042377 -0.010804
N4   0.143536 -0.319757 -0.026781  0.098303 -0.052696
N5  -0.048778  0.536294 -0.021181 -0.113691 -0.126471
N6  -0.061717  0.742160  0.028845 -0.086954 -0.094690
N7  -0.008309  0.701346 -0.076751 -0.155622 -0.005952
N8  -0.020602  0.734001 -0.086199 -0.161347 -0.019393
N9  -0.048323  0.706748 -0.175711 -0.049924 -0.032827
N10 -0.246647  0.613502 -0.038677 -0.166575  0.049262
A1  -0.020357  0.071534 -0.429370 -0.021572 -0.085449
A2   0.343832 -0.056769  0.532098  0.003452  0.092329
A3   0.094700  0.245045 -0.402660 -0.192976  0.077715
A4   0.040557  0.061387  0.781989  0.043956  0.019851
A5  -0.140496  0.022326 -0.655802  0.003271 -0.027470
A6   0.003827  0.151598  0.587389  0.037811 -0.066401
A7  -0.311393  0.102643 -0.626195 -0.008777 -0.050535
A8   0.126001 -0.019461  0.580184  0.092985  0.045610
A9   0.117810  0.111439  0.691568  0.072807  0.068112
A10  0.337254 -0.123264  0.382487  0.152597  0.093989
C1   0.044733 -0.104412  0.013596  0.598824  0.117367
C2   0.051758  0.106214  0.040949 -0.522967  0.125957
C3  -0.031181  0.009296  0.087870  0.405486  0.260914
C4  -0.063342  0.363322 -0.046019 -0.555341  0.014198
C5   0.086143 -0.086466  0.065588  0.622984 -0.084320
C6  -0.000980  0.170190  0.003516 -0.582286  0.063193
C7  -0.043197  0.072796  0.031213  0.536293  0.037413
C8  -0.063609  0.221586 -0.158426 -0.472121 -0.036656
C9   0.058679  0.021834  0.092997  0.625136 -0.036730
C10  0.035921 -0.010321  0.062287  0.472913  0.228170
O1   0.035252 -0.043877 -0.032516  0.045657  0.593308
O2  -0.015200  0.212459 -0.028324 -0.004346 -0.556030
O3   0.035352  0.105723  0.061832 -0.080042  0.525722
O4   0.013652  0.118330 -0.114573  0.063244 -0.475385
O5   0.211363 -0.062298 -0.014451  0.166759  0.583062
O6  -0.101168  0.049057 -0.084777  0.031039 -0.494140
O7   0.081561 -0.132674 -0.002506  0.196083  0.488762
O8   0.000036  0.079363 -0.112483 -0.045916  0.551527
O9  -0.135728  0.168975  0.176076  0.045439  0.339347
O10  0.193353 -0.017253  0.028877  0.050552  0.663103

Factor Variance Explained:
Variance per factor: [4.98625911 4.61063455 3.76643441 3.27188221 3.17310274]
Proportional variance: [0.09972518 0.09221269 0.07532869 0.06543764 0.06346205]
Cumulative variance: [0.09972518 0.19193787 0.26726656 0.33270421 0.39616626]</code></pre>
</div>
</div>
<p>Both the PCA and common factor analysis results support the existence of five latent dimensions that align with the Big Five personality traits. Although the PCA produced 16 components with eigenvalues greater than 1, the scree plot clearly indicated an elbow around the 5th component, reinforcing the theory that the items were designed to measure Extraversion, Neuroticism, Agreeableness, Conscientiousness, and Openness. In contrast, the factor analysis—focused solely on common variance—yielded factor loadings that grouped items into five distinct factors with a cumulative variance of approximately 39.6%. While PCA accounts for both common and unique variance, factor analysis isolates the shared variance among items, making it more suitable for understanding latent constructs. Despite minor differences in loading magnitudes, both methods consistently reveal a five-factor structure, confirming that the underlying personality dimensions remain practically interpretable regardless of the analytical approach.</p>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>